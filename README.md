# Teste de Carga Kafka: Avro vs. JSON com Benchmarking AvanÃ§ado

Este projeto contÃ©m um conjunto de aplicaÃ§Ãµes Java para realizar testes de carga e benchmarks de performance no Confluent Cloud Kafka, comparando a serializaÃ§Ã£o Avro com JSON. O sistema foi projetado para ser altamente configurÃ¡vel, permitindo testes em mÃºltiplos cenÃ¡rios, incluindo diferentes tamanhos de mensagem, compressÃ£o, e modos de benchmark.

## ğŸ“‹ VisÃ£o Geral

O projeto consiste em 4 aplicaÃ§Ãµes Java containerizadas que operam em um tÃ³pico Kafka de 18 partiÃ§Ãµes para maximizar a paralelizaÃ§Ã£o:

1.  **Produtor Avro**: Produz um nÃºmero configurÃ¡vel de mensagens com um schema Avro estruturado.
2.  **Consumidor Avro**: Consome mensagens Avro de forma multi-threaded (um thread por partiÃ§Ã£o) para alta performance.
3.  **Produtor JSON**: Produz o mesmo nÃºmero de mensagens, mas em formato JSON.
4.  **Consumidor JSON**: Consome mensagens JSON, tambÃ©m em modo multi-threaded.

O principal objetivo Ã© fornecer uma **plataforma justa e precisa para comparar Avro e JSON**, medindo throughput, latÃªncia e uso de CPU em diferentes condiÃ§Ãµes.

## ğŸ—ï¸ Estrutura do Projeto

```
teste-carga-avro-vs-json/
â”œâ”€â”€ src/main/
â”‚   â”œâ”€â”€ java/br/com/sandbox/kafka/
â”‚   â”‚   â”œâ”€â”€ AplicacaoPrincipal.java
â”‚   â”‚   â”œâ”€â”€ aplicacoes/
â”‚   â”‚   â”‚   â”œâ”€â”€ ProdutorAvro.java
â”‚   â”‚   â”‚   â”œâ”€â”€ ConsumidorAvro.java
â”‚   â”‚   â”‚   â”œâ”€â”€ ProdutorJson.java
â”‚   â”‚   â”‚   â””â”€â”€ ConsumidorJson.java
â”‚   â”‚   â””â”€â”€ util/
â”‚   â”‚       â”œâ”€â”€ ConfiguracaoKafka.java
â”‚   â”‚       â”œâ”€â”€ GeradorCargaEstruturada.java
â”‚   â”‚       â””â”€â”€ MetricasDesempenho.java
â”‚   â””â”€â”€ resources/
â”‚       â””â”€â”€ avro/
â”‚           â””â”€â”€ MensagemCarga.avsc
â”œâ”€â”€ pom.xml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env (gerado a partir do .env.template)
â”œâ”€â”€ .env.template
â”œâ”€â”€ build-amd64.ps1 (Script de build para Windows)
â”œâ”€â”€ setup.bat (Script de setup inicial para Windows)
â””â”€â”€ README.md
```

## ğŸš€ Como Usar

### PrÃ©-requisitos

*   Java 17+
*   Maven 3.8+
*   Docker e Docker Compose
*   Conta no Confluent Cloud com um cluster Kafka e Schema Registry.
*   API Keys do Confluent Cloud (Cluster e Schema Registry).

### 1. Setup Inicial

Execute o script de setup para criar seu arquivo `.env` a partir do template.

**No Windows:**
```powershell
.\setup.bat
```

### 2. Configurar VariÃ¡veis de Ambiente

Edite o arquivo `.env` recÃ©m-criado e preencha com suas credenciais do Confluent Cloud e as configuraÃ§Ãµes do teste.

```bash
# =================================================
# CONFIGURAÃ‡ÃƒO DA APLICAÃ‡ÃƒO
# =================================================
# Tipo de aplicaÃ§Ã£o a ser executada.
# OpÃ§Ãµes: PRODUTOR_AVRO, CONSUMIDOR_AVRO, PRODUTOR_JSON, CONSUMIDOR_JSON
TIPO_APLICACAO=PRODUTOR_AVRO

# =================================================
# CONFIGURAÃ‡ÃƒO DO BENCHMARK
# =================================================
# Modo de benchmark.
# E2E_PARSE: Mede o tempo de ponta a ponta, incluindo a desserializaÃ§Ã£o/parsing do payload.
# TRANSPORTE: Mede apenas o tempo de transporte, ignorando o conteÃºdo da mensagem (usa ByteArrayDeserializer).
BENCH_MODE=E2E_PARSE

# NÃºmero total de mensagens a serem enviadas pelo produtor.
NUM_MENSAGENS=100000

# Tamanho alvo para cada mensagem em kilobytes (KB).
TAMANHO_MENSAGEM_KB=1024

# NÃºmero de mensagens a serem descartadas no inÃ­cio para o aquecimento (warm-up).
WARMUP_MENSAGENS=1000

# =================================================
# CONFIGURAÃ‡ÃƒO DO KAFKA
# =================================================
# Tipo de compressÃ£o para o produtor.
# OpÃ§Ãµes: none, gzip, snappy, lz4, zstd
COMPRESSION_TYPE=lz4

# NÃºmero de partiÃ§Ãµes do tÃ³pico. Usado pelos produtores para distribuiÃ§Ã£o e consumidores para paralelismo.
NUM_PARTICOES=18

# NÃºmero de threads para o consumidor (idealmente igual ao NUM_PARTICOES).
CONSUMER_THREADS=18

# Se o produtor Avro deve registrar o schema automaticamente.
AUTO_REGISTER_SCHEMAS=true

# =================================================
# CREDENCIAIS DO CONFLUENT CLOUD
# =================================================
# Confluent Cloud Kafka Cluster
KAFKA_BOOTSTRAP_SERVERS=pkc-xxxxx.us-east-1.aws.confluent.cloud:9092
KAFKA_CLUSTER_API_KEY=sua-api-key-cluster
KAFKA_CLUSTER_API_SECRET=seu-api-secret-cluster

# Confluent Cloud Schema Registry
SCHEMA_REGISTRY_URL=https://psrc-xxxxx.us-east-1.aws.confluent.cloud
SCHEMA_REGISTRY_API_KEY=sua-api-key-schema-registry
SCHEMA_REGISTRY_API_SECRET=seu-api-secret-schema-registry
```

### 3. Construir a Imagem Docker

Use o script de build para compilar o projeto com Maven e construir a imagem Docker.

**No Windows (arquitetura amd64):**
```powershell
.\build-amd64.ps1
```

### 4. Executar os Testes

Para cada teste, configure a variÃ¡vel `TIPO_APLICACAO` no arquivo `.env` e execute o `docker-compose`.

**Exemplo: Executar o Produtor Avro**
1.  Edite `.env` e defina `TIPO_APLICACAO=PRODUTOR_AVRO`.
2.  Execute o container:
    ```bash
    docker-compose up
    ```
3.  Aguarde a finalizaÃ§Ã£o. O container irÃ¡ parar automaticamente.

Repita o processo para `CONSUMIDOR_AVRO`, `PRODUTOR_JSON` e `CONSUMIDOR_JSON`.

## ğŸ“Š TÃ³picos Kafka

*   **TÃ³picos de Dados**: `carga-sandbox-avro` e `carga-sandbox-json`.
*   **TÃ³picos de Resultados**: `resultados-carga-sandbox-avro-producer`, `resultados-carga-sandbox-avro-consumer`, etc.

## ğŸ“ˆ MÃ©tricas Coletadas

As mÃ©tricas sÃ£o publicadas em um tÃ³pico de resultados em formato JSON.

Exemplo de saÃ­da (`BENCH_MODE=E2E_PARSE`):
```json
{
  "aplicacao": "PRODUTOR_AVRO",
  "compressionType": "lz4",
  "benchMode": "E2E_PARSE",
  "tamanhoMensagemKB": 1024,
  "totalMensagens": 100000,
  "mensagensSucesso": 99000,
  "mensagensComErro": 0,
  "totalBytes": 101376000,
  "totalMB": "96.68",
  "duracaoSegundos": "15.83",
  "throughputMensagensPorSegundo": "6253.95",
  "throughputMBPorSegundo": "6.11",
  "tempoPorMensagemMs": "0.16",
  "taxaSucessoPorcentagem": "100.00"
}
```
**Nota**: `tempoPorMensagemMs` representa o tempo mÃ©dio de processamento por mensagem: (`duraÃ§Ã£o / nÂº de mensagens`)

## ğŸ”¬ Metodologia de Benchmark: Avro vs. JSON

Para uma comparaÃ§Ã£o justa, o sistema implementa duas estratÃ©gias de teste controladas pela variÃ¡vel `BENCH_MODE`.

### Modo 1: `E2E_PARSE` (Ponta-a-Ponta com Parsing)

Este Ã© o modo de teste mais realista. Ele mede a performance completa do ciclo de vida da mensagem:
*   **Produtor**: Serializa um objeto Java estruturado para Avro ou JSON.
*   **Consumidor**: Desserializa o payload de volta para um objeto Java.

Neste modo, tanto o consumidor Avro quanto o JSON realizam trabalho de parsing, garantindo uma comparaÃ§Ã£o simÃ©trica do custo de CPU e da eficiÃªncia da serializaÃ§Ã£o.

### Modo 2: `TRANSPORTE` (Apenas Transporte)

Este modo foca exclusivamente na eficiÃªncia do transporte (I/O de rede, compressÃ£o, overhead do broker).
*   **Produtor**: Serializa a mensagem normalmente.
*   **Consumidor**: Recebe as mensagens como um array de bytes (`byte[]`) e **nÃ£o faz parsing** do conteÃºdo.

Este modo Ã© Ãºtil para isolar o impacto do tamanho do payload e da compressÃ£o na performance da rede, removendo a sobrecarga da desserializaÃ§Ã£o da anÃ¡lise.

## ğŸ“ Schema Avro Estruturado

O schema Avro foi refatorado para ser totalmente estruturado, abandonando a abordagem anterior de encapsular um JSON. Isso permite que o Avro utilize todo o seu potencial de serializaÃ§Ã£o binÃ¡ria e compactaÃ§Ã£o.

`src/main/resources/avro/MensagemCarga.avsc`:
```json
{
  "type": "record",
  "name": "MensagemCarga",
  "namespace": "br.com.sandbox.kafka.avro",
  "fields": [
    {"name": "id", "type": "string"},
    {"name": "timestamp", "type": "long"},
    {"name": "sequencia", "type": "long"},
    {
      "name": "dados",
      "type": {
        "type": "array",
        "items": {
          "name": "Registro",
          "type": "record",
          "fields": [
            {"name": "campo1", "type": "string"},
            {"name": "campo2", "type": "string"},
            {"name": "campo3", "type": "long"},
            {"name": "campo4", "type": "double"},
            {"name": "campo5", "type": "boolean"}
          ]
        }
      }
    },
    {"name": "versao", "type": "string", "default": "1.0"}
  ]
}
```

## ğŸ› ï¸ SoluÃ§Ã£o de Problemas

*   **Erro de AutenticaÃ§Ã£o**: Verifique todas as API keys no arquivo `.env`.
*   **Erro de Tamanho de Mensagem**: Verifique a configuraÃ§Ã£o `message.max.bytes` no seu tÃ³pico do Confluent Cloud.
*   **Out of Memory**: Ajuste as configuraÃ§Ãµes de memÃ³ria da JVM (`JAVA_OPTS`) no `docker-compose.yml`.

## ğŸ“š DependÃªncias Principais

*   **Kafka Clients**: 3.6.1
*   **Confluent Kafka Avro Serializer**: 7.6.0
*   **Apache Avro**: 1.11.3
*   **Gson**: 2.10.1
*   **SLF4J**: 2.0.9
