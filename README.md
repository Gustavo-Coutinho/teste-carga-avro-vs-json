# AplicaÃ§Ãµes de Teste de Carga Kafka - Avro vs JSON

Sistema de 4 aplicaÃ§Ãµes Java leves para teste de performance no Confluent Cloud Kafka, comparando serializaÃ§Ã£o Avro com JSON puro.

## ğŸ“‹ VisÃ£o Geral

Este projeto contÃ©m 4 aplicaÃ§Ãµes Java independentes que executam em containers Docker:

1. **Produtor Avro** - Produz 10 milhÃµes de mensagens JSON de 2MB serializadas em Avro
2. **Consumidor Avro** - Consome as mensagens Avro
3. **Produtor JSON** - Produz 10 milhÃµes de mensagens JSON de 2MB (sem Avro)
4. **Consumidor JSON** - Consome as mensagens JSON

Todas as aplicaÃ§Ãµes coletam mÃ©tricas de performance e enviam os resultados para tÃ³picos especÃ­ficos.

## ğŸ—ï¸ Estrutura do Projeto

```
kafka-carga-teste/
â”œâ”€â”€ src/main/
â”‚   â”œâ”€â”€ java/br/com/sandbox/kafka/
â”‚   â”‚   â”œâ”€â”€ AplicacaoPrincipal.java
â”‚   â”‚   â”œâ”€â”€ aplicacoes/
â”‚   â”‚   â”‚   â”œâ”€â”€ ProdutorAvro.java
â”‚   â”‚   â”‚   â”œâ”€â”€ ConsumidorAvro.java
â”‚   â”‚   â”‚   â”œâ”€â”€ ProdutorJson.java
â”‚   â”‚   â”‚   â””â”€â”€ ConsumidorJson.java
â”‚   â”‚   â””â”€â”€ util/
â”‚   â”‚       â”œâ”€â”€ ConfiguracaoKafka.java
â”‚   â”‚       â”œâ”€â”€ GeradorMensagemJson.java
â”‚   â”‚       â””â”€â”€ MetricasDesempenho.java
â”‚   â””â”€â”€ resources/
â”‚       â””â”€â”€ avro/
â”‚           â””â”€â”€ MensagemCarga.avsc
â”œâ”€â”€ pom.xml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env (criar baseado em .env.template)
â””â”€â”€ README.md
```

## ğŸš€ Como Usar

### PrÃ©-requisitos

- Java 17+
- Maven 3.8+
- Docker e Docker Compose
- Conta no Confluent Cloud com cluster Kafka configurado
- API Keys do Confluent Cloud (Cluster e Schema Registry)

### 1. Configurar VariÃ¡veis de Ambiente

Crie o arquivo `.env` baseado no template `.env.template`:

```bash
cp .env.template .env
```

Edite o arquivo `.env` e preencha suas credenciais:

```bash
# Tipo de aplicaÃ§Ã£o (PRODUTOR_AVRO, CONSUMIDOR_AVRO, PRODUTOR_JSON, CONSUMIDOR_JSON)
TIPO_APLICACAO=PRODUTOR_AVRO

# Confluent Cloud Kafka Cluster
KAFKA_BOOTSTRAP_SERVERS=pkc-xxxxx.us-east-1.aws.confluent.cloud:9092
KAFKA_CLUSTER_API_KEY=sua-api-key-cluster
KAFKA_CLUSTER_API_SECRET=seu-api-secret-cluster

# Confluent Cloud Schema Registry
SCHEMA_REGISTRY_URL=https://psrc-xxxxx.us-east-1.aws.confluent.cloud
SCHEMA_REGISTRY_API_KEY=sua-api-key-schema-registry
SCHEMA_REGISTRY_API_SECRET=seu-api-secret-schema-registry
```

### 2. Compilar o Projeto

```bash
mvn clean package
```

Isso irÃ¡:
- Gerar as classes Java a partir do schema Avro
- Compilar todas as aplicaÃ§Ãµes
- Criar o JAR executÃ¡vel em `target/kafka-carga-teste-1.0.0.jar`

### 3. Construir a Imagem Docker

```bash
docker-compose build
```

### 4. Executar as AplicaÃ§Ãµes

#### Executar Produtor Avro

```bash
# Editar .env para definir TIPO_APLICACAO=PRODUTOR_AVRO
docker-compose up
```

#### Executar Consumidor Avro

```bash
# Editar .env para definir TIPO_APLICACAO=CONSUMIDOR_AVRO
docker-compose up
```

#### Executar Produtor JSON

```bash
# Editar .env para definir TIPO_APLICACAO=PRODUTOR_JSON
docker-compose up
```

#### Executar Consumidor JSON

```bash
# Editar .env para definir TIPO_APLICACAO=CONSUMIDOR_JSON
docker-compose up
```

## ğŸ“Š TÃ³picos Kafka

### TÃ³picos de Dados

- `carga-sandbox-avro` - Mensagens serializadas em Avro
- `carga-sandbox-json` - Mensagens em JSON puro

### TÃ³picos de Resultados

- `resultados-carga-sandbox-avro-producer` - MÃ©tricas do produtor Avro
- `resultados-carga-sandbox-avro-consumer` - MÃ©tricas do consumidor Avro
- `resultados-carga-sandbox-json-producer` - MÃ©tricas do produtor JSON
- `resultados-carga-sandbox-json-consumer` - MÃ©tricas do consumidor JSON

## ğŸ“ˆ MÃ©tricas Coletadas

Cada aplicaÃ§Ã£o coleta e envia as seguintes mÃ©tricas:

- **Total de mensagens** processadas
- **Total de bytes** transferidos (em MB)
- **DuraÃ§Ã£o** da execuÃ§Ã£o (em segundos)
- **Throughput** (mensagens/segundo e MB/segundo)
- **LatÃªncia mÃ©dia** (ms por mensagem)
- **Taxa de sucesso** (%)
- **Mensagens com erro**

Exemplo de saÃ­da de mÃ©tricas:

```json
{
  "totalMensagens": 10000000,
  "mensagensSucesso": 10000000,
  "mensagensComErro": 0,
  "totalBytes": 20000000000,
  "totalMB": "19073.49",
  "duracaoSegundos": "1234.56",
  "throughputMensagensPorSegundo": "8100.45",
  "throughputMBPorSegundo": "15.45",
  "latenciaMediaMs": "0.12",
  "taxaSucessoPorcentagem": "100.00"
}
```

## ğŸ”§ ConfiguraÃ§Ãµes de Performance

As aplicaÃ§Ãµes sÃ£o otimizadas para throughput com as seguintes configuraÃ§Ãµes:

### Producer
- `acks=1` - ConfirmaÃ§Ã£o do lÃ­der apenas
- `compression.type=lz4` - CompressÃ£o eficiente
- `batch.size=32768` - Lotes de 32KB
- `linger.ms=10` - Aguarda 10ms para formar lotes
- `buffer.memory=64MB` - Buffer de memÃ³ria
- `max.request.size=3MB` - Suporta mensagens de atÃ© 3MB

### Consumer
- `max.poll.records=500` - Processa 500 registros por poll
- `fetch.min.bytes=1024` - MÃ­nimo de 1KB por fetch
- `max.partition.fetch.bytes=3MB` - Suporta mensagens de atÃ© 3MB

## ğŸ³ ConfiguraÃ§Ãµes Docker

### Limites de Recursos

```yaml
resources:
  limits:
    cpus: '2.0'
    memory: 2G
  reservations:
    cpus: '1.0'
    memory: 1G
```

### VariÃ¡veis JVM

```bash
JAVA_OPTS="-Xms512m -Xmx1536m -XX:+UseG1GC -XX:MaxGCPauseMillis=200"
```

## ğŸ“ Schema Avro

O schema `MensagemCarga.avsc` define a estrutura das mensagens:

```json
{
  "type": "record",
  "name": "MensagemCarga",
  "namespace": "br.com.sandbox.kafka.avro",
  "fields": [
    {"name": "id", "type": "string"},
    {"name": "timestamp", "type": "long"},
    {"name": "sequencia", "type": "long"},
    {"name": "dados", "type": "string"},
    {"name": "versao", "type": "string", "default": "1.0"}
  ]
}
```

O campo `dados` contÃ©m um JSON string de aproximadamente 2MB com 10.000 registros.

## ğŸ”’ Schema Registry

As aplicaÃ§Ãµes Avro **criam automaticamente** o schema no Schema Registry do Confluent Cloud na primeira execuÃ§Ã£o atravÃ©s da configuraÃ§Ã£o:

```java
props.put(KafkaAvroSerializerConfig.AUTO_REGISTER_SCHEMAS, "true");
```

O schema Ã© registrado com o subject `carga-sandbox-avro-value`.

## ğŸ› ï¸ SoluÃ§Ã£o de Problemas

### Erro de AutenticaÃ§Ã£o

Verifique se as API Keys estÃ£o corretas no arquivo `.env`:
- `KAFKA_CLUSTER_API_KEY` e `KAFKA_CLUSTER_API_SECRET`
- `SCHEMA_REGISTRY_API_KEY` e `SCHEMA_REGISTRY_API_SECRET`

### Erro de Tamanho de Mensagem

Se as mensagens forem rejeitadas por tamanho, verifique:
1. ConfiguraÃ§Ã£o do broker no Confluent Cloud
2. `max.request.size` no producer
3. `max.partition.fetch.bytes` no consumer

### Out of Memory

Ajuste as configuraÃ§Ãµes JVM no `Dockerfile`:
```bash
JAVA_OPTS="-Xms512m -Xmx2048m -XX:+UseG1GC"
```

## ğŸ“š DependÃªncias Principais

- **Kafka Clients**: 3.6.1
- **Confluent Kafka Avro Serializer**: 7.6.0
- **Apache Avro**: 1.11.3
- **Gson**: 2.10.1
- **SLF4J**: 2.0.9

## ğŸ§ª Ordem de ExecuÃ§Ã£o Recomendada

1. **Produtor Avro** â†’ Gera mensagens Avro
2. **Consumidor Avro** â†’ Consome mensagens Avro
3. **Produtor JSON** â†’ Gera mensagens JSON
4. **Consumidor JSON** â†’ Consome mensagens JSON

Aguarde cada aplicaÃ§Ã£o finalizar antes de iniciar a prÃ³xima.

## ğŸ“Š ComparaÃ§Ã£o Avro vs JSON

ApÃ³s executar todas as 4 aplicaÃ§Ãµes, compare as mÃ©tricas nos tÃ³picos de resultados para avaliar:

- **Throughput**: Mensagens/segundo e MB/segundo
- **LatÃªncia**: Tempo mÃ©dio por mensagem
- **Tamanho**: Bytes totais transferidos
- **Performance**: DuraÃ§Ã£o total da execuÃ§Ã£o

## ğŸ¤ ContribuiÃ§Ãµes

Este projeto foi desenvolvido para testes de carga e comparaÃ§Ã£o de performance entre Avro e JSON no Confluent Cloud Kafka.

## ğŸ“„ LicenÃ§a

Projeto de uso interno para testes e benchmarking.
